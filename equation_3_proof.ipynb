{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Equation\n",
    "\n",
    "Let's now look at a nonlinear equation:\n",
    "### $$\\partial^2_x f(x,y) + \\partial^2_y f(x,y) - 2f(x,y) + f(x,y)^2 = 0$$\n",
    "\n",
    "with the following Dirichlet border conditions:\n",
    "### $$\\forall (x,y) \\in \\partial \\mathbb{D}, f(x,y) =  \\phi(x,y)$$ \n",
    "where:\n",
    "* $\\mathbb{D} = [0;1]^2$ is the square of side length $1$.\n",
    "* $\\partial \\mathbb{D} = \\{ 0;1\\} \\times [0;1] \\cup  [0;1]\\times \\{0;1\\}$ is the border of $\\mathbb{D}$.\n",
    "* $\\phi$ is a function $\\partial \\mathbb{D} \\to \\mathbb{R}$.\n",
    "\n",
    "Let $L \\in \\mathbb{N}^*$: we want to build $u : \\{0, ..., L-1\\} \\times \\{0, ..., L-1\\} \\to \\mathbb{R}$ such that for every $0 \\leq i < L$ and $0 \\leq j < L$, $u(i,j)$ approaches $f(\\frac {i} {L}, \\frac {j} {L})$. We call $\\mathcal{D}$ the lattice $\\{0, ..., L\\}^2$, and $\\partial \\mathcal{D} = \\{0,L\\} \\times \\{0, ..., L\\} \\sqcup \\{0, ..., L\\} \\times \\{0,L \\}$ its border.\n",
    "\n",
    "## 2. Random Walk\n",
    "\n",
    "In order to handle the quadratic extra term, we're going to add a layer of complexity by allowing our process to branch. Not only does our random walk move and die: it can also duplicate! \n",
    "\n",
    "This begs a more rigourous explanation: let $(i,j) \\in \\mathcal{D}$ be a position in the lattice. We introduce a sequence $(X_n)_{n \\in \\mathbb{N}}$ of random vectors of variable dimension, the components  of which stand for the branches of our process that haven't died yet (the heads of the hydra that haven't been cut). The $(X_n)$ are defined such that:\n",
    "* The sequence starts at $(i,j)$: $X_0 = [(i,j)]$\n",
    "* For every $n \\in \\mathbb{N}$, every branch that hasn't reached the border can:\n",
    " * **Die** with probability $\\alpha = \\frac {1} {L^2} $, in which case there is no corresponding component in the subsequent vector $X_{n+1}$.\n",
    " * **Live** with probability $\\beta = \\alpha = \\frac {1} {L^2} $: move up down, left or right with probability $1/4$. The corresponding component in $X_{n+1}$ contains the new position.\n",
    " * **Duplicate**: don't move, but the next vector will have (at least) an extra component containing the branche's present coordinates.\n",
    "* Every branch that has reached the border stays put.\n",
    " \n",
    "## 3. Approximation\n",
    "\n",
    "### 1. Defining $u(i,j)$\n",
    "\n",
    "We introduce the stopping times:\n",
    "* $T = \\inf \\{n \\in \\mathbb{N} | X_n = \\dagger \\}$ is the first time at which **all branches have died**.\n",
    "* $\\tau = \\inf \\{n \\in \\mathbb{N} | X_n \\in \\partial \\mathcal{D} \\}$ is the first time at which **all branches have reached the border**.\n",
    "\n",
    "\n",
    "Let $N_n$ be the number of components in the vector $X_n$.\n",
    "\n",
    " \n",
    "We define $u(i,j) = \\mathbb{E}\\big[ \\prod\\limits^{N_n}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T} | X_0 = [(i,j)] \\big]$, where $\\tilde{\\phi}$ sends $(i,j) \\in \\partial \\mathcal{D}$ to $\\phi(i/L, j/L)$.\n",
    "\n",
    "### 2. What equation does $u(i,j)$ follow?\n",
    "\n",
    "Ok, let's show that $u$ defined as above does indeed provide us with a reasonable approximation for our differential equation. For this, we condition on the first step in the random walk, *i.e.* whether the walk dies, duplicates or marches on on its first step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        u(i,j) &= \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T} | X_0 = [(i,j)] \\big] \\\\\n",
    " &=  \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 0} | X_0 = [(i,j)] \\big] \\ \\ \\ \\text{(die)} \\\\\n",
    " & \\ + \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1} | X_0 = [(i,j)] \\big] \\ \\ \\ \\text{(keep walking)} \\\\\n",
    " & \\ + \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 2} | X_0 = [(i,j)] \\big] \\ \\ \\ \\text{(duplicate)}  \n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now consider these three terms separately, assuming here that initially $(i,j) \\in \\partial \\mathcal{D}$ (we shall examine this case later):\n",
    "\n",
    "* If $N_1 = 0$ then $T = 1$ and since $(i,j)$ is not on the border $\\partial \\mathcal{D}$, $\\tau > 0$: it cannot be the case that $\\tau < T$, therefore the first term in the sum is always $0$.\n",
    "\n",
    "\n",
    "* If $N_1 = 1$, then conditioning further with respect to the neighbour reached yields:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1} | X_0 = [(i,j)] \\big] &= \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1}\\mathbb{1}_{X_1 = [(i+1, j)]} | X_0 = [(i,j)] \\big] \\\\\n",
    "        &+ \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1}\\mathbb{1}_{X_1 = [(i-1, j)]} | X_0 = [(i,j)] \\big] \\\\\n",
    "        &+ \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1}\\mathbb{1}_{X_1 = [(i, j+1)]} | X_0 = [(i,j)] \\big] \\\\\n",
    "        &+ \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1}\\mathbb{1}_{X_1 = [(i, j-1)]} | X_0 = [(i,j)] \\big] \n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "Therefore:\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 1} | X_0 = [(i,j)] \\big] &= \\frac {(1 - \\alpha - \\beta)} {4} [u(i+1,j) + u(i-1, j) + u(i, j+1) + u(i, j-1)] \\\\\n",
    "        &= (1 - \\alpha - \\beta) \\tilde{\\Delta}u(i,j) + (1 - \\alpha - \\beta) u(i,j)\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "* Finally, if $N_2 = 1$, then the process has split into two hereby independent branches. All subsequent vectors $X_n$ can be split into two parts, which each part corresponding to the  components stemming from either branch: let $m_\\tau$ be the number of components stemming from the first branch at time $\\tau$. Then: \n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "         \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 2} | X_0 = [(i,j)] \\big]&= \n",
    "         \\mathbb{P}[N_1 = 2] \\cdot\n",
    "         \\mathbb{E}_{[(i,j)]}\\big[ \\prod\\limits^{m_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau})\\prod\\limits^{N_\\tau}_{i = m_\\tau + 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T} | X_1 = [(i, j), (i,j)] \\big] \\\\\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "We now consider the random sequences $(Y_n)_{n \\in \\mathbb{N}}$ and $(Z_n)_{n \\in \\mathbb{N}}$ of truncated vectors:\n",
    "\n",
    "$$\\forall n \\in \\mathbb{N}, \\  Y_n = [X^{(i)}_{n+1}]_{1 \\leq i \\leq m_n} \\ \\ \\text{and} \\ \\ Z_n = [X^{(i + m_{n})}_{n+1}]_{1 \\leq i \\leq N_n-m_{n}}$$\n",
    "\n",
    "Then $(Y_n)$ and $(Z_n)$ are independent Markov Chains initially in $(i,j)$, with same transition as $(X_n)$. Letting $\\tau^Y$ and $\\tau^Z$ be the associated stopping times, we have $\\{\\tau < T \\} = \\{\\tau^Y < T \\} \\cap \\{\\tau^Z < T \\}$ hence $\\mathbb{1}_{\\{\\tau < T \\}} = \\mathbb{1}_{\\{\\tau^Y < T \\}} \\cdot \\mathbb{1}_{\\{\\tau^Z < T \\}}$. Moreover $N_{\\tau^Y} = m_\\tau$ and $N_{\\tau^Z} = N_\\tau - m_\\tau$. By independence:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "         \\mathbb{E}\\big[ \\prod\\limits^{N_\\tau}_{i = 1} \\tilde{\\phi}(X^{(i)}_{\\tau}) \\mathbb{1}_{\\tau < T}\\mathbb{1}_{N_1 = 2} | X_0 = [(i,j)] \\big]&= \n",
    "         \\beta \\cdot \\mathbb{E} \\big[\\prod\\limits^{N_{\\tau^Y}}_{i = 1} \\tilde{\\phi}(Y^{(i)}_{\\tau}) \\mathbb{1}_{\\tau^Y < T} | Y_0 = [(i, j)] \\big] \\\\\n",
    "                & \\ \\ \\ \\ \\ \\times \\mathbb{E}\\big[\\prod\\limits^{N_{\\tau^Z}}_{i = 1} \\tilde{\\phi}(Z^{(i)}_{\\tau}) \\mathbb{1}_{\\tau^Z < T} | Z_0 = [ (i,j)] \\big] \\\\\n",
    "                &= \\beta u(i,j)^2\n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with the following equation for $u(i,j)$ (when $(i,j) \\notin \\partial \\mathcal{D}$):\n",
    "$$u(i,j) = (1 - \\alpha - \\beta) \\tilde{\\Delta}u(i,j) + (1 - \\alpha - \\beta) u(i,j) + \\beta u(i,j)^2$$\n",
    "\n",
    "\n",
    "Or equivalently:\n",
    "$$(1 - \\alpha - \\beta) \\tilde{\\Delta}u(i,j) - (\\alpha + \\beta) u(i,j) + \\beta u(i,j)^2 = 0 \\ \\ \\ (*)$$\n",
    "### 3. Back to continuous functions\n",
    "\n",
    "Once again, define $f : \\mathbb{D} \\to \\mathbb{R}$ by $f(x,y) = u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)$, and recall that $\\alpha = \\beta = \\frac {1} {L^2}$. Then for every $(x,y) \\in \\mathbb{D}$, multiplying both sides of $(*)$ by $L^2$ yields:\n",
    "\n",
    "$$ (1 - \\frac {2} {L^2}) \\cdot \\frac {\\tilde{\\Delta}u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)} {(1/L)^2} - 2 u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor) + u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)^2 = 0$$\n",
    "\n",
    "When $L \\to \\infty$:\n",
    "$$\\frac {\\tilde{\\Delta}u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)} {(1/L)^2} \\to \\Delta f(x,y) \\ \\ \\ \\text{and} \\ \\ \\ u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor) \\to f(x,y)$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    " $$\\boxed{\\forall (x,y) \\in \\mathbb{D},\\Delta f(x,y) - 2 f(x,y) + f(x,y)^2 =0}$$\n",
    " \n",
    " \n",
    "### 4. Border conditions\n",
    "Let $(x,y) \\in \\partial \\mathbb{D}$: then $(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor) \\in \\partial \\mathcal{D}$. Let $i = \\lfloor xL \\rfloor$ and $j = \\lfloor yL \\rfloor$, and consider once again the random walk $(X_n)_{n \\in \\mathbb{N}}$ initially in $(i,j)$ defined above. Since $(x,y) \\in \\partial \\mathbb{D}$, $X_0 = [(i,j)]$ is such that $(i,j) \\in \\partial \\mathcal{D}$. This implies that $\\mathbb{P}[X_n = [(i,j)]]$ almost surely for every $n \\in \\mathbb{N}$. In particular $\\tau = 0$ and $T = + \\infty$, so that $u(i,j) = \\tilde{\\phi}(i,j)$. \n",
    "\n",
    "Since this is true for every $L \\in \\mathbb{N}^*$, by taking the limit as $L \\to \\infty$ we also have:\n",
    "$$\\boxed{\\forall (x,y) \\in \\partial \\mathbb{D}, f(x,y) = \\phi(x,y)}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
