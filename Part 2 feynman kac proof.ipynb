{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Second equation:   \n",
    "\n",
    "## 1. Equation\n",
    "\n",
    "### $$\\partial^2_x f(x,y) + \\partial^2_y f(x,y) - \\gamma f(x,y) = 0 $$\n",
    "with the following Dirichlet border conditions:\n",
    "### $$\\forall (x,y) \\in \\partial \\mathbb{D}, f(x,y) =  \\phi(x,y)$$ \n",
    "where:\n",
    "* $\\mathbb{D} = [0;1]^2$ is the square of side length $1$.\n",
    "* $\\partial \\mathbb{D} = \\{ 0;1\\} \\times [0;1] \\cup  [0;1]\\times \\{0;1\\}$ is the border of $\\mathbb{D}$.\n",
    "* $\\phi$ is a function $\\partial \\mathbb{D} \\to \\mathbb{R}$.\n",
    "\n",
    "\n",
    "Let $L \\in \\mathbb{N}^*$: we want to build $u : \\{0, ..., L-1\\} \\times \\{0, ..., L-1\\} \\to \\mathbb{R}$ such that for every $0 \\leq i < L$ and $0 \\leq j < L$, $u(i,j)$ approaches $f(\\frac {i} {L}, \\frac {j} {L})$. We call $\\mathcal{D}$ the lattice $\\{0, ..., L\\}^2$, and $\\partial \\mathcal{D} = \\{0,L\\} \\times \\{0, ..., L\\} \\sqcup \\{0, ..., L\\} \\times \\{0,L \\}$ its border.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Walk\n",
    "\n",
    "Define $\\beta = \\ln (\\gamma/L^2 + 1)$. For every $(i,j) \\in \\mathcal{D}$, let $(X_n)_{n \\in \\mathbb{N}}$ be the two-dimensional random walk initially in $(i,j)$, such that for every $n \\in \\mathbb{N}$:\n",
    "* if $X_n = (k,l)$ is on the border $\\partial \\mathcal{D}$, the walk stays put with probability $1$: $\\mathbb{P}[X_{n+1} = (k,l)] = 1$.\n",
    "* else,  $X_n = (k,l) \\in \\mathcal{D} \\setminus \\partial \\mathcal{D}$, we chose a neighbour of $(k,l)$ with uniform probability:\n",
    " * $\\mathbb{P}[X_{n+1} = (k+1,l)] = 1/4$\n",
    " * $\\mathbb{P}[X_{n+1} = (k-1,l)] = 1/4$\n",
    " * $\\mathbb{P}[X_{n+1} = (k,l+1)] = 1/4$\n",
    " * $\\mathbb{P}[X_{n+1} = (k,l-1)] = 1/4$\n",
    "\n",
    "\n",
    "\n",
    "## 3. Approximation\n",
    "\n",
    "### 1. Defining $u(i,j)$\n",
    "Let $T = \\inf \\{ n \\in \\mathbb{N}, X_n \\in \\partial \\mathcal{D} \\}$ be the first time the border of $\\mathcal{D}$ is reached. Consider the function $u : \\mathcal{D} \\to \\mathbb{R}$ defined on every $(i,j) \\in \\mathcal{D}$ by: \n",
    "### $$u(i,j) = \\mathbb{E}_{(i,j)}\\big[\\phi(X_T) exp \\big( - \\beta T \\big)\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What equation does $u(i,j)$ follow?\n",
    "\n",
    "Since the walk is symmetric, conditionning with respect to the first step yields for every $(i,j) \\notin \\partial \\mathbb{D}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        u(i,j) &= \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_T)exp \\big( - \\beta T \\big) | X_0 = (i,j), X_1 = (i+1, j)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{T})exp \\big( - \\beta T \\big) | X_0 = (i,j), X_1 = (i-1, j)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{T})exp \\big( - \\beta T \\big) | X_0 = (i,j), X_1 = (i, j+1)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{T})exp \\big( - \\beta T \\big) | X_0 = (i,j), X_1 = (i, j-1)  \\big]\n",
    "    \\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Markov's property implies that the sequence $(X_{n+1})_{n \\in \\mathbb{N}}$ is also a Markov chain with same transition as $(X_{n})_{n \\in \\mathbb{N}}$, and with initial position $X_1$. Therefore:\n",
    "$$u(i,j) = \\frac {e^{-\\beta}} {4} [u(i+1,j) + u(i,j+1) + u(i-1,j) + u(i,j-1)]$$\n",
    "\n",
    " $$\\frac {e^{-\\beta}} {4} [u(i+1,j) + u(i,j+1) + u(i-1,j) + u(i,j-1) - 4 u(i,j)] - (1 - e^{-\\beta})u(i,j) = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\tilde{\\Delta}$ be the discretised Laplacian, sending every function $f: \\mathbb{D} \\to \\mathbb{R}$ to the function $$\\tilde{\\Delta}f : (i,j) \\mapsto \\frac 1 4 \\sum\\limits_{(k,l) \\sim(i,j)} [f(k,l) - f(i,j)]$$\n",
    "\n",
    "The previous equality can therefore be rewritten as follows:\n",
    "\n",
    "$$\\tilde{\\Delta}u(i,j)  - (e^{\\beta} - 1)u(i,j) = 0 \\ \\ (*)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Back to continuous functions\n",
    "\n",
    "Intuitively, $v_n$ checks a discretised version of the following equation:\n",
    "$$\\Delta f(x,y) - \\gamma f(x,y)$$\n",
    "\n",
    "Let's make this statement more precise: define $f : \\mathbb{D} \\to \\mathbb{R}$ by $f(x,y) = u(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)$. Then for every $(x,y) \\in \\mathbb{D}$, multiplying both sides of $(*)$ by $L^2$ yields:\n",
    "$$\\frac {1}{4 (1/L)^2} [f(x+1/L, y) + f(x-1/L, y) + f(x, y+1/L) + f(x, y-1/L) - 4 f(x,y)f(x,y)] - \\gamma f(x,y) = 0$$\n",
    "\n",
    "Therefore when $L \\to \\infty$:\n",
    "\n",
    " $$\\boxed{\\forall (x,y) \\in \\mathbb{D},\\Delta f(x,y) - \\gamma f(x,y) =0}$$\n",
    "\n",
    "\n",
    "\n",
    "### 4. Border conditions\n",
    "\n",
    "Let $(x,y) \\in \\partial \\mathbb{D}$: then $(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor) \\in \\partial \\mathcal{D}$. Let $i = \\lfloor xL \\rfloor$ and $j = \\lfloor yL \\rfloor$, and consider once again the random walk $(X_n)_{n \\in \\mathbb{N}}$ initially in $(i,j)$ defined above. Since $X_0 = (i,j) \\in \\partial \\mathcal{D}$, the border is reached immediately, and since the $X_n$ stays constant, the sum $\\sum\\limits^{n}_{j = 0} \\mathbb{1}_{\\{ X_j \\notin \\partial{\\mathbb{D}} \\}}$ equals $0$ for every $n \\in \\mathbb{N}$, including for $n = T$. Therefore $u(i,j) = \\tilde{\\phi}(i,j) = \\phi(x,y)$.\n",
    "\n",
    "Since this is true for every $L \\in \\mathbb{N}^*$, by taking the limit as $L \\to \\infty$ we also have:\n",
    "$$\\boxed{\\forall (x,y) \\in \\partial \\mathbb{D}, f(x,y) = \\phi(x,y)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Watching the process unfold through time\n",
    "### 1. Defining $v_n(i,j)$\n",
    "\n",
    "\n",
    "Define for every $n \\in \\mathbb{N}$ the function $v_n : \\mathcal{D} \\to \\mathbb{R}$ sending every $(i,j) \\in \\mathcal{D}$ to: \n",
    "\n",
    "$$v_n(i,j) = \\mathbb{E}_{(i,j)}\\big[\\phi(X_n) exp \\big( - \\beta \\sum\\limits^{n}_{j = 0} \\mathbb{1}_{\\{ X_j \\notin \\partial{\\mathbb{D}} \\}}\\big)\\big]$$\n",
    "\n",
    "### 2. What equation does $v_n(i,j)$ follow?\n",
    "\n",
    "Since the walk is symmetric a calculation very similar to the one above leads to:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{aligned}\n",
    "        v_{n+1}(i,j) &= \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{n+1})exp \\big( - \\beta \\sum_\\limits{i = 0}^{n+1} \\mathbb{1}_{X_i \\notin \\partial{\\mathbb{D}} }\\big) | X_0 = (i,j), X_1 = (i+1, j)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{n+1})exp \\big( - \\beta \\sum_\\limits{i = 0}^{n+1} \\mathbb{1}_{X_i \\notin \\partial{\\mathbb{D}} }\\big) | X_0 = (i,j), X_1 = (i-1, j)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{n+1})exp \\big( - \\beta \\sum_\\limits{i = 0}^{n+1} \\mathbb{1}_{X_i \\notin \\partial{\\mathbb{D}} }\\big) | X_0 = (i,j), X_1 = (i, j+1)  \\big] \\\\\n",
    " &+ \\frac {1} {4} \\mathbb{E} \\big[ \\phi(X_{n+1})exp \\big( - \\beta \\sum_\\limits{i = 0}^{n+1} \\mathbb{1}_{X_i \\notin \\partial{\\mathbb{D}} }\\big) | X_0 = (i,j), X_1 = (i, j-1)  \\big] \\\\\n",
    " &= \\frac {e^{-\\beta}} {4} [v_n(i+1,j) + v_n(i,j+1) + v_n(i-1,j) + v_n(i,j-1)]\n",
    "    \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Therefore:\n",
    " $$v_{n+1}(i,j) - v_n(i,j) =  \\frac {e^{-\\beta}} {4} [v_n(i+1,j) + v_n(i,j+1) + v_n(i-1,j) + v_n(i,j-1) - 4 v_n(i,j)] - (e^{\\beta} - 1)v_n(i,j) = 0 \\ \\ (**)$$\n",
    "\n",
    "\n",
    "### 3. Back to continuous functions\n",
    "Once again, intuitively, $v_n$ checks a discretised version of the following equation:\n",
    "$$ \\partial_t f(x,y,t) = \\Delta f(x,y,t) - \\gamma f(x,y,t)$$\n",
    "\n",
    "Let's make this statement more precise: define $f : \\mathbb{R}^{*}_{+} \\times \\mathbb{D} \\to \\mathbb{R}$ by $f(t,x,y) = v_{\\lfloor nL^2\\rfloor}(\\lfloor xL \\rfloor, \\lfloor yL \\rfloor)$.\n",
    "\n",
    "Then for every $(t,(x,y)) \\in \\mathbb{R}^{*}_{+} \\times \\mathbb{D}$, multiplying both sides of $(**)$ by $L^2$ yields:\n",
    "\n",
    "$$\\frac {f(t + 1/L^2,x,y) - f(t,x,y)} {(1/L^2)}  = \\frac {f(t, x+1/L, y) + f(t, x-1/L, y) + f(t, x, y+1/L) + f(t, x, y-1/L) - 4 f(t, x,y)}{4 (1/L)^2}  - \\gamma f(t,x,y)$$\n",
    "\n",
    "Therefore when $L \\to \\infty$:\n",
    "\n",
    "$$\\boxed{\\forall (t, (x,y)) \\in \\mathbb{R}^*_+ \\times\\partial \\mathbb{D},\\partial_t f(t,x,y) = \\Delta f(t,x,y) - \\gamma f(t,x,y)} $$\n",
    "\n",
    "The border conditions are also verified:\n",
    "$$\\boxed{\\forall (t, (x,y)) \\in \\mathbb{R}^*_+ \\times\\partial \\mathbb{D}, f(x,y) = \\phi(x,y)}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
